{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-variable Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-variable linear regression\n",
    "Predicting exam score - regression using three inputs (x1, x2, x3)\n",
    "\n",
    "|x1 (quiz 1)|x2 (quiz 2)|x3 (mid 1)|Y (final)\n",
    "|---|---|---|---|\n",
    "|73|80|75|152|\n",
    "|93|88|93|185|\n",
    "|89|91|90|180|\n",
    "|96|98|100|196|\n",
    "|73|66|70|142|\n",
    "Test Scores for General Psychology ( https://goo.gl/g2T8Kp )\n",
    "\n",
    "### Matrix multiplication\n",
    "#### dot product(=scalar product, 내적)\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "#### Hypothesis\n",
    "$$ H(x) = w x + b $$$$ H(x_1, x_2, x_3) = w_1 x_1 + w_2 x_2 + w_3 x_3 + b $$\n",
    "\n",
    "\n",
    "### Hypothesis using matrix\n",
    "#### Many x instances\n",
    "$$ \\begin{pmatrix} x_{ 11 }  x_{ 12 }  x_{ 13 } \\\\ x_{ 21 } x_{ 22 }  x_{ 23 } \\\\ x_{ 31 }  x_{ 32 }  x_{ 33 }\\\\ x_{ 41 }  x_{ 42 }  x_{ 43 }\\\\ x_{ 51 }  x_{ 52 }  x_{ 53 }\\end{pmatrix} \\cdot \\begin{pmatrix} w_{ 1 } \\\\ w_{ 2 } \\\\ w_{ 3 } \\end{pmatrix}=\\begin{pmatrix} x_{ 11 }w_{ 1 }+x_{ 12 }w_{ 2 }+x_{ 13 }w_{ 3 } \\\\ x_{ 21 }w_{ 1 }+x_{ 22 }w_{ 2 }+x_{ 23 }w_{ 3 }\\\\ x_{ 31 }w_{ 1 }+x_{ 32 }w_{ 2 }+x_{ 33 }w_{ 3 } \\\\ x_{ 41 }w_{ 1 }+x_{ 42 }w_{ 2 }+x_{ 43 }w_{ 3 } \\\\ x_{ 51 }w_{ 1 }+x_{ 52 }w_{ 2 }+x_{ 53 }w_{ 3 } \\end{pmatrix} $$$$ [5, 3] \\cdot [3, 1] = [5, 1] $$$$ H(X) = XW $$\n",
    "\n",
    "5는 데이터(instance)의 수, 3은 변수(feature)의 수, 1은 결과\n",
    "\n",
    "\n",
    "### WX vs XW\n",
    "#### Theory (Lecture) :\n",
    "$$ H(x) = Wx + b  $$\n",
    "\n",
    "#### TensorFlow (Implementation) :\n",
    "$$ H(X) = XW $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Example (2 variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 335.280823 |    -4.0663 |     1.1220 |  -6.065215\n",
      "   50 |  76.037262 |    -0.8001 |     1.6209 |  -4.978779\n",
      "  100 |  18.959263 |     0.7151 |     1.8781 |  -4.429109\n",
      "  150 |   6.310240 |     1.4125 |     2.0104 |  -4.134423\n",
      "  200 |   3.445082 |     1.7284 |     2.0768 |  -3.961648\n",
      "  250 |   2.743659 |     1.8667 |     2.1075 |  -3.847750\n",
      "  300 |   2.525401 |     1.9225 |     2.1184 |  -3.762738\n",
      "  350 |   2.417754 |     1.9402 |     2.1181 |  -3.692262\n",
      "  400 |   2.337300 |     1.9403 |     2.1114 |  -3.629400\n",
      "  450 |   2.264998 |     1.9325 |     2.1008 |  -3.570778\n",
      "  500 |   2.196328 |     1.9213 |     2.0881 |  -3.514729\n",
      "  550 |   2.130126 |     1.9085 |     2.0741 |  -3.460409\n",
      "  600 |   2.066037 |     1.8953 |     2.0595 |  -3.407385\n",
      "  650 |   2.003917 |     1.8819 |     2.0444 |  -3.355424\n",
      "  700 |   1.943679 |     1.8686 |     2.0293 |  -3.304398\n",
      "  750 |   1.885258 |     1.8555 |     2.0141 |  -3.254230\n",
      "  800 |   1.828595 |     1.8425 |     1.9990 |  -3.204873\n",
      "  850 |   1.773636 |     1.8297 |     1.9841 |  -3.156293\n",
      "  900 |   1.720329 |     1.8171 |     1.9693 |  -3.108468\n",
      "  950 |   1.668625 |     1.8048 |     1.9547 |  -3.061379\n",
      " 1000 |   1.618474 |     1.7926 |     1.9403 |  -3.015011\n"
     ]
    }
   ],
   "source": [
    "# 데이터 생성\n",
    "x1_data = [1, 0, 3, 0, 5]\n",
    "x2_data = [0, 2, 0, 4, 0]\n",
    "y_data  = [1, 2, 3, 4, 5]\n",
    "\n",
    "# 가중치 랜덤 배정\n",
    "W1 = tf.Variable(tf.random.uniform((1,), -10.0, 10.0))\n",
    "W2 = tf.Variable(tf.random.uniform((1,), -10.0, 10.0))\n",
    "b  = tf.Variable(tf.random.uniform((1,), -10.0, 10.0))\n",
    "\n",
    "# 학습률 지정\n",
    "learning_rate = tf.Variable(0.001)\n",
    "\n",
    "# GradientTape을 이용해서 W가 최소가 되게하는 값을 찾음\n",
    "for i in range(1000+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = W1 * x1_data + W2 * x2_data + b # Hypothesis 수식\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data)) # Cost 수식\n",
    "    W1_grad, W2_grad, b_grad = tape.gradient(cost, [W1, W2, b]) # Cost를 W1, W2, b에 관해 미분한 값 저장 \n",
    "    \n",
    "    # 지정한 학습률을 곱하여 배정\n",
    "    W1.assign_sub(learning_rate * W1_grad) \n",
    "    W2.assign_sub(learning_rate * W2_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    # 50번마다 한 번씩 결과값 출력\n",
    "    if i % 50 == 0:\n",
    "        print(\"{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.6f}\".format(\n",
    "          i, cost.numpy(), W1.numpy()[0], W2.numpy()[0], b.numpy()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Example (2 variables with Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |  36.403778 |    -0.6231 |    -0.3508 |  -0.961774\n",
      "   50 |   9.372901 |     0.2914 |     0.1682 |  -0.557764\n",
      "  100 |   2.639858 |     0.7060 |     0.4867 |  -0.347756\n",
      "  150 |   0.825069 |     0.8912 |     0.6846 |  -0.235665\n",
      "  200 |   0.284990 |     0.9721 |     0.8088 |  -0.174012\n",
      "  250 |   0.106844 |     1.0062 |     0.8873 |  -0.138953\n",
      "  300 |   0.042677 |     1.0195 |     0.9372 |  -0.118279\n",
      "  350 |   0.018044 |     1.0241 |     0.9690 |  -0.105598\n",
      "  400 |   0.008188 |     1.0250 |     0.9893 |  -0.097477\n",
      "  450 |   0.004138 |     1.0246 |     1.0022 |  -0.092026\n",
      "  500 |   0.002439 |     1.0239 |     1.0104 |  -0.088173\n",
      "  550 |   0.001710 |     1.0230 |     1.0156 |  -0.085299\n",
      "  600 |   0.001384 |     1.0223 |     1.0188 |  -0.083036\n",
      "  650 |   0.001227 |     1.0217 |     1.0207 |  -0.081161\n",
      "  700 |   0.001142 |     1.0212 |     1.0218 |  -0.079538\n",
      "  750 |   0.001088 |     1.0207 |     1.0224 |  -0.078080\n",
      "  800 |   0.001046 |     1.0203 |     1.0227 |  -0.076735\n",
      "  850 |   0.001011 |     1.0199 |     1.0227 |  -0.075468\n",
      "  900 |   0.000980 |     1.0196 |     1.0226 |  -0.074258\n",
      "  950 |   0.000949 |     1.0192 |     1.0225 |  -0.073089\n",
      " 1000 |   0.000921 |     1.0189 |     1.0222 |  -0.071954\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 Matrix 형태로 생성\n",
    "x_data = [\n",
    "    [1., 0., 3., 0., 5.],\n",
    "    [0., 2., 0., 4., 0.]\n",
    "]\n",
    "y_data  = [1, 2, 3, 4, 5]\n",
    "\n",
    "# 가중치는 1*2의 Matrix 형태를 가짐\n",
    "# random weight\n",
    "W = tf.Variable(tf.random.uniform((1, 2), -1.0, 1.0))\n",
    "b = tf.Variable(tf.random.uniform((1,), -1.0, 1.0))\n",
    "\n",
    "# 학습률 지정\n",
    "learning_rate = tf.Variable(0.001)\n",
    "\n",
    "for i in range(1000+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.matmul(W, x_data) + b # (1, 2) * (2, 5) = (1, 5)\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "\n",
    "        W_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "        W.assign_sub(learning_rate * W_grad)\n",
    "        b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(\"{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.6f}\".format(\n",
    "            i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], b.numpy()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis without b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |  16.019751 |    -0.1985 |     0.3424 |    -0.6835\n",
      "   50 |   5.635924 |     0.0582 |     0.6809 |    -0.1215\n",
      "  100 |   2.141112 |     0.1997 |     0.8238 |     0.2356\n",
      "  150 |   0.862825 |     0.2786 |     0.8808 |     0.4641\n",
      "  200 |   0.367090 |     0.3227 |     0.9015 |     0.6112\n",
      "  250 |   0.167513 |     0.3468 |     0.9074 |     0.7064\n",
      "  300 |   0.085210 |     0.3593 |     0.9082 |     0.7684\n",
      "  350 |   0.050615 |     0.3649 |     0.9074 |     0.8090\n",
      "  400 |   0.035731 |     0.3663 |     0.9067 |     0.8359\n",
      "  450 |   0.029064 |     0.3651 |     0.9063 |     0.8539\n",
      "  500 |   0.025846 |     0.3624 |     0.9064 |     0.8661\n",
      "  550 |   0.024085 |     0.3587 |     0.9069 |     0.8746\n",
      "  600 |   0.022948 |     0.3544 |     0.9076 |     0.8807\n",
      "  650 |   0.022085 |     0.3497 |     0.9086 |     0.8852\n",
      "  700 |   0.021348 |     0.3449 |     0.9097 |     0.8887\n",
      "  750 |   0.020676 |     0.3400 |     0.9109 |     0.8916\n",
      "  800 |   0.020042 |     0.3350 |     0.9121 |     0.8940\n",
      "  850 |   0.019434 |     0.3301 |     0.9133 |     0.8960\n",
      "  900 |   0.018848 |     0.3252 |     0.9146 |     0.8979\n",
      "  950 |   0.018280 |     0.3203 |     0.9158 |     0.8997\n",
      " 1000 |   0.017730 |     0.3155 |     0.9171 |     0.9013\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 앞의 코드에서 bias(b)를 행렬에 추가\n",
    "x_data = [\n",
    "    [1., 1., 1., 1., 1.], # bias(b)\n",
    "    [1., 0., 3., 0., 5.], \n",
    "    [0., 2., 0., 4., 0.]\n",
    "]\n",
    "y_data  = [1, 2, 3, 4, 5]\n",
    "\n",
    "W = tf.Variable(tf.random.uniform((1, 3), -1.0, 1.0)) # [1, 3]으로 변경하고, b 삭제\n",
    "\n",
    "# 학습률 지정\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "for i in range(1000+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.matmul(W, x_data) # b가 없다\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "\n",
    "    grads = tape.gradient(cost, [W])\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads,[W]))\n",
    "    if i % 50 == 0:\n",
    "        print(\"{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.4f}\".format(\n",
    "            i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], W.numpy()[0][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b를 X Matrix에 포함시켜서 가중치가 2->3(w1, w2, w3)개로 늘어났음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Gradient\n",
    "- tf.train.GradientDescentOptimizer(): optimizer\n",
    "- optimizer.apply_gradients(): update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | cost\n",
      "    0 |  21.726822\n",
      "   50 |   0.258689\n",
      "  100 |   0.176868\n",
      "  150 |   0.120926\n",
      "  200 |   0.082678\n",
      "  250 |   0.056528\n",
      "  300 |   0.038649\n",
      "  350 |   0.026424\n",
      "  400 |   0.018067\n",
      "  450 |   0.012352\n",
      "  500 |   0.008445\n",
      "  550 |   0.005774\n",
      "  600 |   0.003948\n",
      "  650 |   0.002699\n",
      "  700 |   0.001845\n",
      "  750 |   0.001262\n",
      "  800 |   0.000863\n",
      "  850 |   0.000590\n",
      "  900 |   0.000403\n",
      "  950 |   0.000276\n",
      " 1000 |   0.000189\n"
     ]
    }
   ],
   "source": [
    "# Multi-variable linear regression (1)\n",
    "\n",
    "# tf.constant : 텐서플로우 변하지 않는 상수 생성\n",
    "X = tf.constant([[1., 2.], \n",
    "                 [3., 4.]])\n",
    "y = tf.constant([[1.5], [3.5]])\n",
    "\n",
    "# Random weight\n",
    "W = tf.Variable(tf.random.normal((2, 1)))\n",
    "b = tf.Variable(tf.random.normal((1,)))\n",
    "\n",
    "# Create an optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "# 반복횟수 지정\n",
    "n_epoch = 1000+1\n",
    "print(\"epoch | cost\")\n",
    "\n",
    "for i in range(n_epoch):\n",
    "    # Use tf.GradientTape() to record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = tf.matmul(X, W) + b # Hypothesis \n",
    "        cost = tf.reduce_mean(tf.square(y_pred - y)) # Cost\n",
    "\n",
    "    # calculates the gradients of the loss\n",
    "    grads = tape.gradient(cost, [W, b])\n",
    "    \n",
    "    # updates parameters (W and b)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, [W, b]))\n",
    "    if i % 50 == 0:\n",
    "        print(\"{:5} | {:10.6f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting exam score\n",
    "regression using three inputs (x1, x2, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)  # for reproducibility(재현성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 5793889.5000\n",
      "   50 |   64291.1562\n",
      "  100 |     715.2903\n",
      "  150 |       9.8461\n",
      "  200 |       2.0152\n",
      "  250 |       1.9252\n",
      "  300 |       1.9210\n",
      "  350 |       1.9177\n",
      "  400 |       1.9145\n",
      "  450 |       1.9114\n",
      "  500 |       1.9081\n",
      "  550 |       1.9050\n",
      "  600 |       1.9018\n",
      "  650 |       1.8986\n",
      "  700 |       1.8955\n",
      "  750 |       1.8923\n",
      "  800 |       1.8892\n",
      "  850 |       1.8861\n",
      "  900 |       1.8829\n",
      "  950 |       1.8798\n",
      " 1000 |       1.8767\n"
     ]
    }
   ],
   "source": [
    "# data and label\n",
    "x1 = [ 73.,  93.,  89.,  96.,  73.]\n",
    "x2 = [ 80.,  88.,  91.,  98.,  66.]\n",
    "x3 = [ 75.,  93.,  90., 100.,  70.]\n",
    "Y  = [152., 185., 180., 196., 142.]\n",
    "\n",
    "# weights random 지정\n",
    "w1 = tf.Variable(10.)\n",
    "w2 = tf.Variable(10.)\n",
    "w3 = tf.Variable(10.)\n",
    "b  = tf.Variable(10.)\n",
    "\n",
    "# 학습률 지정\n",
    "learning_rate = 0.000001\n",
    "\n",
    "for i in range(1000+1):\n",
    "    # tf.GradientTape() to record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = w1 * x1 +  w2 * x2 + w3 * x3 + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "    # calculates the gradients of the cost\n",
    "    w1_grad, w2_grad, w3_grad, b_grad = tape.gradient(cost, [w1, w2, w3, b])\n",
    "    \n",
    "    # update w1,w2,w3 and b\n",
    "    w1.assign_sub(learning_rate * w1_grad)\n",
    "    w2.assign_sub(learning_rate * w2_grad)\n",
    "    w3.assign_sub(learning_rate * w3_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "\n",
    "    if i % 50 == 0:\n",
    "      print(\"{:5} | {:12.4f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-variable linear regression (1)\n",
    "- random 초기화: tf.random_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |   11325.9121\n",
      "   50 |     135.3618\n",
      "  100 |      11.1817\n",
      "  150 |       9.7940\n",
      "  200 |       9.7687\n",
      "  250 |       9.7587\n",
      "  300 |       9.7489\n",
      "  350 |       9.7389\n",
      "  400 |       9.7292\n",
      "  450 |       9.7194\n",
      "  500 |       9.7096\n",
      "  550 |       9.6999\n",
      "  600 |       9.6903\n",
      "  650 |       9.6806\n",
      "  700 |       9.6709\n",
      "  750 |       9.6612\n",
      "  800 |       9.6517\n",
      "  850 |       9.6421\n",
      "  900 |       9.6325\n",
      "  950 |       9.6229\n",
      " 1000 |       9.6134\n"
     ]
    }
   ],
   "source": [
    "# data and label\n",
    "x1 = [ 73.,  93.,  89.,  96.,  73.]\n",
    "x2 = [ 80.,  88.,  91.,  98.,  66.]\n",
    "x3 = [ 75.,  93.,  90., 100.,  70.]\n",
    "Y  = [152., 185., 180., 196., 142.]\n",
    "\n",
    "# random weights\n",
    "w1 = tf.Variable(tf.random.normal((1,)))\n",
    "w2 = tf.Variable(tf.random.normal((1,)))\n",
    "w3 = tf.Variable(tf.random.normal((1,)))\n",
    "b  = tf.Variable(tf.random.normal((1,)))\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "for i in range(1000+1):\n",
    "    # tf.GradientTape() to record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = w1 * x1 +  w2 * x2 + w3 * x3 + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "    # calculates the gradients of the cost\n",
    "    w1_grad, w2_grad, w3_grad, b_grad = tape.gradient(cost, [w1, w2, w3, b])\n",
    "    \n",
    "    # update w1,w2,w3 and b\n",
    "    w1.assign_sub(learning_rate * w1_grad)\n",
    "    w2.assign_sub(learning_rate * w2_grad)\n",
    "    w3.assign_sub(learning_rate * w3_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "\n",
    "    if i % 50 == 0:\n",
    "      print(\"{:5} | {:12.4f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-variable linear regression (2)\n",
    "- Matrix 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | cost\n",
      "    0 |  9563.7852\n",
      "  100 |     4.5003\n",
      "  200 |     3.3124\n",
      "  300 |     3.3014\n",
      "  400 |     3.2907\n",
      "  500 |     3.2800\n",
      "  600 |     3.2693\n",
      "  700 |     3.2587\n",
      "  800 |     3.2482\n",
      "  900 |     3.2378\n",
      " 1000 |     3.2274\n",
      " 1100 |     3.2170\n",
      " 1200 |     3.2067\n",
      " 1300 |     3.1963\n",
      " 1400 |     3.1861\n",
      " 1500 |     3.1760\n",
      " 1600 |     3.1659\n",
      " 1700 |     3.1559\n",
      " 1800 |     3.1458\n",
      " 1900 |     3.1359\n",
      " 2000 |     3.1260\n"
     ]
    }
   ],
   "source": [
    "# Data Matirx 형태로 지정\n",
    "data = np.array([\n",
    "    # X1,   X2,    X3,   y\n",
    "    [ 73.,  80.,  75., 152. ],\n",
    "    [ 93.,  88.,  93., 185. ],\n",
    "    [ 89.,  91.,  90., 180. ],\n",
    "    [ 96.,  98., 100., 196. ],\n",
    "    [ 73.,  66.,  70., 142. ]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# slice data\n",
    "X = data[:, :-1]  # [모두, 처음부터 마지막 1열 빼고]\n",
    "y = data[:, [-1]] # [모두, 마지막 1열]\n",
    "\n",
    "# weight random 배정\n",
    "W = tf.Variable(tf.random.normal((3, 1)))\n",
    "b = tf.Variable(tf.random.normal((1,)))\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "# hypothesis, prediction function\n",
    "def predict(X):\n",
    "    return tf.matmul(X, W) + b\n",
    "\n",
    "print(\"epoch | cost\")\n",
    "\n",
    "# 반복횟수 지정\n",
    "n_epochs = 2000\n",
    "for i in range(n_epochs+1):\n",
    "    # tf.GradientTape() to record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = tf.reduce_mean((tf.square(predict(X) - y)))\n",
    "\n",
    "    # calculates the gradients of the loss\n",
    "    W_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "\n",
    "    # updates parameters (W and b)\n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"{:5} | {:10.4f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.8544998 ],\n",
       "       [ 0.5379935 ],\n",
       "       [-0.36304417]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# W1, W2, W3값 출력\n",
    "W.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.57518363], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b값 출력\n",
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       "array([[150.61446],\n",
       "       [185.47362],\n",
       "       [180.75873],\n",
       "       [193.87575],\n",
       "       [144.89778]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hypothesis 값 출력\n",
    "tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[152.0, 185.0, 180.0, 196.0, 142.0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y # labels, 실제값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[150.61446],\n",
       "       [185.47362],\n",
       "       [180.75873],\n",
       "       [193.87575],\n",
       "       [144.89778]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X).numpy() # prediction, 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[182.18462],\n",
       "       [173.83945]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 데이터에 대한 예측\n",
    "\n",
    "predict([[ 89.,  95.,  92.],[ 84.,  92.,  85.]]).numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
