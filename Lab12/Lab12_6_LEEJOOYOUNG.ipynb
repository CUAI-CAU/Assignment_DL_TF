{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab12-6_LEEJOOYOUNG.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_vc8Q8Hp0aw",
        "outputId": "8fd37f69-57ab-4644-8c62-123a5d59479c"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "### matplotlib 한글 폰트 설정 #############################\n",
        "from matplotlib import font_manager, rc\n",
        "## for window #####\n",
        "font_name = font_manager.FontProperties(fname=\"/content/drive/MyDrive/malgun.ttf\").get_name()\n",
        "rc('font', family=font_name)\n",
        "## for mac #####\n",
        "#rc('font', family='AppleGothic') #for mac\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYccU0cTp7K0"
      },
      "source": [
        "sources = [['I', 'feel', 'hungry'],\n",
        "     ['tensorflow', 'is', 'very', 'difficult'],\n",
        "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
        "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
        "targets = [['나는', '배가', '고프다'],\n",
        "           ['텐서플로우는', '매우', '어렵다'],\n",
        "           ['텐서플로우는', '딥러닝을', '위한', '프레임워크이다'],\n",
        "           ['텐서플로우는', '매우', '빠르게', '변화한다']]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szzU52Q-qDpB",
        "outputId": "673ca2e8-db5d-4a26-a3b2-463cd5bfa02a"
      },
      "source": [
        "# vocabulary for sources\n",
        "s_vocab = list(set(sum(sources, [])))\n",
        "s_vocab.sort()\n",
        "s_vocab = ['<pad>'] + s_vocab\n",
        "source2idx = {word : idx for idx, word in enumerate(s_vocab)}\n",
        "idx2source = {idx : word for idx, word in enumerate(s_vocab)}\n",
        "\n",
        "pprint(source2idx)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<pad>': 0,\n",
            " 'I': 1,\n",
            " 'a': 2,\n",
            " 'changing': 3,\n",
            " 'deep': 4,\n",
            " 'difficult': 5,\n",
            " 'fast': 6,\n",
            " 'feel': 7,\n",
            " 'for': 8,\n",
            " 'framework': 9,\n",
            " 'hungry': 10,\n",
            " 'is': 11,\n",
            " 'learning': 12,\n",
            " 'tensorflow': 13,\n",
            " 'very': 14}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHhWPmGoqEcn",
        "outputId": "8e5cbc60-d4c7-4c88-b252-e5ba68f98355"
      },
      "source": [
        "# vocabulary for targets\n",
        "t_vocab = list(set(sum(targets, [])))\n",
        "t_vocab.sort()\n",
        "t_vocab = ['<pad>', '<bos>', '<eos>'] + t_vocab\n",
        "target2idx = {word : idx for idx, word in enumerate(t_vocab)}\n",
        "idx2target = {idx : word for idx, word in enumerate(t_vocab)}\n",
        "\n",
        "pprint(target2idx)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<bos>': 1,\n",
            " '<eos>': 2,\n",
            " '<pad>': 0,\n",
            " '고프다': 3,\n",
            " '나는': 4,\n",
            " '딥러닝을': 5,\n",
            " '매우': 6,\n",
            " '배가': 7,\n",
            " '변화한다': 8,\n",
            " '빠르게': 9,\n",
            " '어렵다': 10,\n",
            " '위한': 11,\n",
            " '텐서플로우는': 12,\n",
            " '프레임워크이다': 13}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NT8ljeOqIUh"
      },
      "source": [
        "def preprocess(sequences, max_len, dic, mode = 'source'):\n",
        "    assert mode in ['source', 'target'], 'source와 target 중에 선택해주세요.'\n",
        "    \n",
        "    if mode == 'source':\n",
        "        # preprocessing for source (encoder)\n",
        "        s_input = list(map(lambda sentence : [dic.get(token) for token in sentence], sequences))\n",
        "        s_len = list(map(lambda sentence : len(sentence), s_input))\n",
        "        s_input = pad_sequences(sequences = s_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "        return s_len, s_input\n",
        "    \n",
        "    elif mode == 'target':\n",
        "        # preprocessing for target (decoder)\n",
        "        # input\n",
        "        t_input = list(map(lambda sentence : ['<bos>'] + sentence + ['<eos>'], sequences))\n",
        "        t_input = list(map(lambda sentence : [dic.get(token) for token in sentence], t_input))\n",
        "        t_len = list(map(lambda sentence : len(sentence), t_input))\n",
        "        t_input = pad_sequences(sequences = t_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "        \n",
        "        # output\n",
        "        t_output = list(map(lambda sentence : sentence + ['<eos>'], sequences))\n",
        "        t_output = list(map(lambda sentence : [dic.get(token) for token in sentence], t_output))\n",
        "        t_output = pad_sequences(sequences = t_output, maxlen = max_len, padding = 'post', truncating = 'post')\n",
        "        \n",
        "        return t_len, t_input, t_output"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpQiZ3hcqLGk",
        "outputId": "a5381729-e229-4341-b1ad-c9902aa716ad"
      },
      "source": [
        "# preprocessing for source\n",
        "s_max_len = 10\n",
        "s_len, s_input = preprocess(sequences = sources,\n",
        "                            max_len = s_max_len, dic = source2idx, mode = 'source')\n",
        "print(s_len, s_input)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 4, 7, 5] [[ 1  7 10  0  0  0  0  0  0  0]\n",
            " [13 11 14  5  0  0  0  0  0  0]\n",
            " [13 11  2  9  8  4 12  0  0  0]\n",
            " [13 11 14  6  3  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fDFH4FuqOFy",
        "outputId": "d13fe4af-881a-4022-ae8c-6ef0d3870fe9"
      },
      "source": [
        "# preprocessing for target\n",
        "t_max_len = 12\n",
        "t_len, t_input, t_output = preprocess(sequences = targets,\n",
        "                                      max_len = t_max_len, dic = target2idx, mode = 'target')\n",
        "print(t_len, t_input, t_output)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 5, 6, 6] [[ 1  4  7  3  2  0  0  0  0  0  0  0]\n",
            " [ 1 12  6 10  2  0  0  0  0  0  0  0]\n",
            " [ 1 12  5 11 13  2  0  0  0  0  0  0]\n",
            " [ 1 12  6  9  8  2  0  0  0  0  0  0]] [[ 4  7  3  2  0  0  0  0  0  0  0  0]\n",
            " [12  6 10  2  0  0  0  0  0  0  0  0]\n",
            " [12  5 11 13  2  0  0  0  0  0  0  0]\n",
            " [12  6  9  8  2  0  0  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23rDB-MkqQjL"
      },
      "source": [
        "# hyper-parameters\n",
        "epochs = 100\n",
        "batch_size = 4\n",
        "learning_rate = .005\n",
        "total_step = epochs / batch_size\n",
        "buffer_size = 100\n",
        "n_batch = buffer_size//batch_size\n",
        "embedding_dim = 32\n",
        "units = 128\n",
        "\n",
        "# input\n",
        "data = tf.data.Dataset.from_tensor_slices((s_len, s_input, t_len, t_input, t_output))\n",
        "data = data.shuffle(buffer_size = buffer_size)\n",
        "data = data.batch(batch_size = batch_size)\n",
        "# s_mb_len, s_mb_input, t_mb_len, t_mb_input, t_mb_output = iterator.get_next()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-SlpHJxqS_r"
      },
      "source": [
        "def gru(units):\n",
        "    return tf.keras.layers.GRU(units, \n",
        "                               return_sequences=True, \n",
        "                               return_state=True, \n",
        "                               recurrent_activation='sigmoid', \n",
        "                               recurrent_initializer='glorot_uniform')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60Luh-QxqVvl"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.enc_units)\n",
        "        \n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)\n",
        "#         print(\"state: {}\".format(state.shape))\n",
        "#         print(\"output: {}\".format(state.shape))\n",
        "              \n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WNj4Iu4qZLy"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.dec_units)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "        # used for attention\n",
        "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        \n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        # * `score = FC(tanh(FC(EO) + FC(H)))`\n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
        "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
        "                \n",
        "        #* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the *1st axis*, since the shape of score is *(batch_size, max_length, 1)*. `Max_length` is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis.\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        \n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        # * `context vector = sum(attention weights * EO, axis = 1)`. Same reason as above for choosing axis as 1.\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        \n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        # * `embedding output` = The input to the decoder X is passed through an embedding layer.\n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        # * `merged vector = concat(embedding output, context vector)`\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        \n",
        "        # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x)\n",
        "        \n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        \n",
        "        # output shape == (batch_size * 1, vocab)\n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, state, attention_weights\n",
        "        \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ_LSXBdqed5"
      },
      "source": [
        "encoder = Encoder(len(source2idx), embedding_dim, units, batch_size)\n",
        "decoder = Decoder(len(target2idx), embedding_dim, units, batch_size)\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = 1 - np.equal(real, 0)\n",
        "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
        "    \n",
        "#     print(\"real: {}\".format(real))\n",
        "#     print(\"pred: {}\".format(pred))\n",
        "#     print(\"mask: {}\".format(mask))\n",
        "#     print(\"loss: {}\".format(tf.reduce_mean(loss_)))\n",
        "    \n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "# creating optimizer\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# creating check point (Object-based saving)\n",
        "checkpoint_dir = './data_out/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                encoder=encoder,\n",
        "                                decoder=decoder)\n",
        "\n",
        "# create writer for tensorboard\n",
        "summary_writer = tf.summary.create_file_writer(logdir=checkpoint_dir)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22intFBJqhjf",
        "outputId": "bedaef3b-6ef4-450e-f76f-1c0326fe99c7"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    \n",
        "    hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for i, (s_len, s_input, t_len, t_input, t_output) in enumerate(data):\n",
        "        loss = 0\n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_output, enc_hidden = encoder(s_input, hidden)\n",
        "            \n",
        "            dec_hidden = enc_hidden\n",
        "            \n",
        "            dec_input = tf.expand_dims([target2idx['<bos>']] * batch_size, 1)\n",
        "            \n",
        "            #Teacher Forcing: feeding the target as the next input\n",
        "            for t in range(1, t_input.shape[1]):\n",
        "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "                \n",
        "                loss += loss_function(t_input[:, t], predictions)\n",
        "            \n",
        "                dec_input = tf.expand_dims(t_input[:, t], 1) #using teacher forcing\n",
        "                \n",
        "        batch_loss = (loss / int(t_input.shape[1]))\n",
        "        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        variables = encoder.variables + decoder.variables\n",
        "        \n",
        "        gradient = tape.gradient(loss, variables)\n",
        "        \n",
        "        optimizer.apply_gradients(zip(gradient, variables))\n",
        "        \n",
        "    if epoch % 10 == 0:\n",
        "        #save model every 10 epoch\n",
        "        print('Epoch {} Loss {:.4f} Batch Loss {:.4f}'.format(epoch,\n",
        "                                            total_loss / n_batch,\n",
        "                                            batch_loss.numpy()))\n",
        "        checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Loss 0.0396 Batch Loss 0.9900\n",
            "Epoch 10 Loss 0.0374 Batch Loss 0.9361\n",
            "Epoch 20 Loss 0.0345 Batch Loss 0.8628\n",
            "Epoch 30 Loss 0.0331 Batch Loss 0.8279\n",
            "Epoch 40 Loss 0.0310 Batch Loss 0.7746\n",
            "Epoch 50 Loss 0.0272 Batch Loss 0.6801\n",
            "Epoch 60 Loss 0.0181 Batch Loss 0.4531\n",
            "Epoch 70 Loss 0.0113 Batch Loss 0.2830\n",
            "Epoch 80 Loss 0.0069 Batch Loss 0.1727\n",
            "Epoch 90 Loss 0.0040 Batch Loss 0.1008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMFj__ZRqmYg"
      },
      "source": [
        "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    \n",
        "#     sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    \n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang['<bos>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "        \n",
        "        # storing the attention weigths to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += idx2target[predicted_id] + ' '\n",
        "\n",
        "        if idx2target.get(predicted_id) == '<eos>':\n",
        "            return result, sentence, attention_plot\n",
        "        \n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot\n",
        "\n",
        "# result, sentence, attention_plot = evaluate(sentence, encoder, decoder, source2idx, target2idx,\n",
        "#                                             s_max_len, t_max_len)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JClloJodqqCh"
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    \n",
        "    fontdict = {'fontsize': 14}\n",
        "    \n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTUvl8XOqsue"
      },
      "source": [
        "def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
        "        \n",
        "    print('Input: {}'.format(sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    \n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCpTqRIYqwLt",
        "outputId": "a75b1421-d051-4dcd-c9a4-4fabede993b4"
      },
      "source": [
        "#restore checkpoint\n",
        "\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fdaf6d00590>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uvaeHgBMqyYg",
        "outputId": "95509efa-c05f-4a3f-9351-f873270690ee"
      },
      "source": [
        "sentence = 'I feel hungry'\n",
        "# sentence = 'tensorflow is a framework for deep learning'\n",
        "\n",
        "translate(sentence, encoder, decoder, source2idx, target2idx, s_max_len, t_max_len)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "findfont: Font family ['Malgun Gothic'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: I feel hungry\n",
            "Predicted translation: 나는 배가 고프다 <eos> \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45208 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45716 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48176 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44032 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44256 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54532 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 45796 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45208 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45716 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48176 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44032 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44256 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54532 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 45796 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_hRWPPSq08a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}