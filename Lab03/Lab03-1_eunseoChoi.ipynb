{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-03 Liner Regression and How to minimize cost LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function in pure Python : 원래 numpy 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.000 |   74.66667\n",
      "-2.429 |   54.85714\n",
      "-1.857 |   38.09524\n",
      "-1.286 |   24.38095\n",
      "-0.714 |   13.71429\n",
      "-0.143 |    6.09524\n",
      " 0.429 |    1.52381\n",
      " 1.000 |    0.00000\n",
      " 1.571 |    1.52381\n",
      " 2.143 |    6.09524\n",
      " 2.714 |   13.71429\n",
      " 3.286 |   24.38095\n",
      " 3.857 |   38.09524\n",
      " 4.429 |   54.85714\n",
      " 5.000 |   74.66667\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1, 2, 3])\n",
    "Y = np.array([1, 2, 3])\n",
    "\n",
    "## 비용 함수\n",
    "def cost_func(W, X, Y):\n",
    "    c = 0\n",
    "    for i in range(len(X)):\n",
    "        ## cost function : (wx-y)제곱의 평균\n",
    "        c += (W * X[i] - Y[i]) ** 2\n",
    "    return c / len(X)\n",
    "\n",
    "for feed_W in np.linspace(-3, 5, num=15):\n",
    "    curr_cost = cost_func(feed_W, X, Y)\n",
    "    print(\"{:6.3f} | {:10.5f}\".format(feed_W, curr_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function in TensorFlow - 텐서플로우 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.000 |   74.66667\n",
      "-2.429 |   54.85714\n",
      "-1.857 |   38.09524\n",
      "-1.286 |   24.38095\n",
      "-0.714 |   13.71429\n",
      "-0.143 |    6.09524\n",
      " 0.429 |    1.52381\n",
      " 1.000 |    0.00000\n",
      " 1.571 |    1.52381\n",
      " 2.143 |    6.09524\n",
      " 2.714 |   13.71429\n",
      " 3.286 |   24.38095\n",
      " 3.857 |   38.09524\n",
      " 4.429 |   54.85714\n",
      " 5.000 |   74.66667\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1, 2, 3])\n",
    "Y = np.array([1, 2, 3])\n",
    "\n",
    "## 비용함수\n",
    "def cost_func(W, X, Y):\n",
    "    hypothesis = X * W\n",
    "    ##텐서플로의 내장 함수 사용\n",
    "    return tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "W_values = np.linspace(-3, 5, num=15)\n",
    "cost_values = []\n",
    "\n",
    "for feed_W in W_values:\n",
    "    curr_cost = cost_func(feed_W, X, Y)\n",
    "    cost_values.append(curr_cost)\n",
    "    print(\"{:6.3f} | {:10.5f}\".format(feed_W, curr_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent 원리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nalpha=0.01\\ngradient=tf.reduce_mean(tf.multiply)\\n##w값 갱신\\ndescent=W-tf.multiply(alpha,gradient)\\nW.assign(descent)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "alpha=0.01\n",
    "gradient=tf.reduce_mean(tf.multiply)\n",
    "##w값 갱신\n",
    "descent=W-tf.multiply(alpha,gradient)\n",
    "W.assign(descent)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent 실제 값 대입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 다음에도 동일한 값을 사용하려면 seed값 지정\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 369568.2812 | -267.280273\n",
      "   10 | 142098.7500 | -165.355255\n",
      "   20 | 54636.8750 | -102.153580\n",
      "   30 | 21007.8379 | -62.963478\n",
      "   40 |  8077.4995 | -38.662479\n",
      "   50 |  3105.7939 | -23.593918\n",
      "   60 |  1194.1759 | -14.250199\n",
      "   70 |   459.1598 |  -8.456345\n",
      "   80 |   176.5466 |  -4.863691\n",
      "   90 |    67.8821 |  -2.635958\n",
      "  100 |    26.1006 |  -1.254585\n",
      "  110 |    10.0357 |  -0.398023\n",
      "  120 |     3.8587 |   0.133113\n",
      "  130 |     1.4837 |   0.462461\n",
      "  140 |     0.5705 |   0.666683\n",
      "  150 |     0.2193 |   0.793317\n",
      "  160 |     0.0843 |   0.871840\n",
      "  170 |     0.0324 |   0.920530\n",
      "  180 |     0.0125 |   0.950722\n",
      "  190 |     0.0048 |   0.969444\n",
      "  200 |     0.0018 |   0.981053\n",
      "  210 |     0.0007 |   0.988251\n",
      "  220 |     0.0003 |   0.992715\n",
      "  230 |     0.0001 |   0.995483\n",
      "  240 |     0.0000 |   0.997199\n",
      "  250 |     0.0000 |   0.998263\n",
      "  260 |     0.0000 |   0.998923\n",
      "  270 |     0.0000 |   0.999332\n",
      "  280 |     0.0000 |   0.999586\n",
      "  290 |     0.0000 |   0.999743\n"
     ]
    }
   ],
   "source": [
    "x_data = [1., 2., 3., 4.]\n",
    "y_data = [1., 3., 5., 7.]\n",
    "\n",
    "## 1개짜리 번수로 만들어서 지정\n",
    "W = tf.Variable(tf.random.normal([1], -100., 100.))\n",
    "\n",
    "for step in range(300):\n",
    "    ## 예측함수\n",
    "    hypothesis = W * X\n",
    "    ## 비용함수\n",
    "    cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "    ## 학습률\n",
    "    alpha = 0.01\n",
    "    ##기울기\n",
    "    gradient = tf.reduce_mean(tf.multiply(tf.multiply(W, X) - Y, X))\n",
    "    ## w값 갱신\n",
    "    descent = W - tf.multiply(alpha, gradient)\n",
    "    W.assign(descent)\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print('{:5} | {:10.4f} | {:10.6f}'.format(step, cost.numpy(), W.numpy()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cost는 0으로 수렴, W는 특정 값으로 수렴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |    74.6667 |   4.813334\n",
      "   10 |    28.7093 |   3.364572\n",
      "   20 |    11.0387 |   2.466224\n",
      "   30 |     4.2444 |   1.909177\n",
      "   40 |     1.6320 |   1.563762\n",
      "   50 |     0.6275 |   1.349578\n",
      "   60 |     0.2413 |   1.216766\n",
      "   70 |     0.0928 |   1.134412\n",
      "   80 |     0.0357 |   1.083346\n",
      "   90 |     0.0137 |   1.051681\n",
      "  100 |     0.0053 |   1.032047\n",
      "  110 |     0.0020 |   1.019871\n",
      "  120 |     0.0008 |   1.012322\n",
      "  130 |     0.0003 |   1.007641\n",
      "  140 |     0.0001 |   1.004738\n",
      "  150 |     0.0000 |   1.002938\n",
      "  160 |     0.0000 |   1.001822\n",
      "  170 |     0.0000 |   1.001130\n",
      "  180 |     0.0000 |   1.000700\n",
      "  190 |     0.0000 |   1.000434\n",
      "  200 |     0.0000 |   1.000269\n",
      "  210 |     0.0000 |   1.000167\n",
      "  220 |     0.0000 |   1.000103\n",
      "  230 |     0.0000 |   1.000064\n",
      "  240 |     0.0000 |   1.000040\n",
      "  250 |     0.0000 |   1.000025\n",
      "  260 |     0.0000 |   1.000015\n",
      "  270 |     0.0000 |   1.000009\n",
      "  280 |     0.0000 |   1.000006\n",
      "  290 |     0.0000 |   1.000004\n"
     ]
    }
   ],
   "source": [
    "x_data = [1., 2., 3., 4.]\n",
    "y_data = [1., 3., 5., 7.]\n",
    "\n",
    "W = tf.Variable([5.0])\n",
    "\n",
    "for step in range(300):\n",
    "    hypothesis = W * X\n",
    "    cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "    alpha = 0.01\n",
    "    gradient = tf.reduce_mean(tf.multiply(tf.multiply(W, X) - Y, X))\n",
    "    descent = W - tf.multiply(alpha, gradient)\n",
    "    W.assign(descent)\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print('{:5} | {:10.4f} | {:10.6f}'.format(\n",
    "            step, cost.numpy(), W.numpy()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어떤 랜덤 값이여도 W, b는 특정 값으로 수렴, cost는 0으로 수렴"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
